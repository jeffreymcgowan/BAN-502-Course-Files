rm(list=ls()) #clean env

---
title: "Module 4 Random Forests"
author: "Jeffrey McGowan"
date: "9/24/2023"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
#Module 4 Random Forests

```{r, include = FALSE}
library(tidyverse)
library(tidymodels)
library(mice) #package for imputation
library(VIM) #visualizing missingness
library(ranger) #for random forests
library(randomForest) #also for random forests
library(caret)
library(skimr)
library(GGally)
library(gridExtra)
library(vip) #variable importance
```

Load data from the CSData.csv file.  
```{r}
drug = read_csv("drug_data.csv")
```

Structure and summary
```{R}
str(drug)
summary(drug)
skim(drug)
```

```{r echo=FALSE, message=FALSE, error=FALSE, warning=FALSE} 

names(drug) = c("ID", "Age", "Gender", "Education", "Country", "Ethnicity", "Nscore", "Escore", "Oscore", "Ascore", "Cscore", "Impulsive", "SS", "Alcohol", "Amphet", "Amyl", "Benzos", "Caff", "Cannabis", "Choc", "Coke", "Crack", "Ecstasy", "Heroin", "Ketamine", "Legalh", "LSD", "Meth", "Mushrooms", "Nicotine", "Semer", "VSA")

drug[drug == "CL0"] = "No" 
drug[drug == "CL1"] = "No" 
drug[drug == "CL2"] = "Yes" 
drug[drug == "CL3"] = "Yes" 
drug[drug == "CL4"] = "Yes" 
drug[drug == "CL5"] = "Yes" 
drug[drug == "CL6"] = "Yes"

drug_clean = drug %>% mutate_at(vars(Age:Ethnicity), funs(as_factor)) %>%
  mutate(Age = factor(Age, labels = c("18_24", "25_34", "35_44", "45_54","55_64", "65_"))) %>%
  mutate(Gender = factor(Gender, labels = c("Male", "Female"))) %>% 
  mutate(Education = factor(Education, labels = c("Under16", "At16", "At17", "At18", "SomeCollege","ProfessionalCert", "Bachelors", "Masters", "Doctorate"))) %>% 
  mutate(Country = factor(Country, labels = c("USA", "NewZealand", "Other", "Australia", "Ireland","Canada","UK"))) %>% 
  mutate(Ethnicity = factor(Ethnicity, labels = c("Black", "Asian", "White", "White/Black", "Other", "White/Asian", "Black/Asian"))) %>% 
  mutate_at(vars(Alcohol:VSA), funs(as_factor)) %>% select(-ID)

```

```{r}

str(drug_clean)

```

```{r}

drug_clean = drug_clean %>% select(!(Alcohol:Mushrooms)) %>% select(!(Semer:VSA))

```

```{r Question 1}

#Check for missing data in our “drug_clean” dataframe. 
#True/False: There is missingness in the dataset. FALSE
skim(drug_clean)

```

```{r Question 2}

# Split the dataset into training (70%) and testing (30%) sets. Use a set.seed of 1234. Stratify by the “Nicotine” variable. How many rows are in the training set? #---------->1318

set.seed(1234) 
drug_split = initial_split(drug_clean, prop = 0.7, strata = Nicotine) #70% in training
train = training(drug_split)
test = testing(drug_split)
  
```

```{r Question 3}

# Create appropriate visualizations (12 in all) to examine the relationships between each variable and “Nicotine”. Use grid.arrange (from the gridExtra package) to organize these visuals (perhaps in groups of four visualizations?).
# 
# True/False: Individuals in the 18-24 age group are proportionally more likely to be Nicotine users than not.

p1 = ggplot(train, aes(x = Age, fill = Nicotine)) + geom_bar(position = "fill")
p2 = ggplot(train, aes(x = Gender, fill = Nicotine)) + geom_bar(position = "fill")
p3 = ggplot(train, aes(x = Education, fill = Nicotine)) + geom_bar(position = "fill")
p4 = ggplot(train, aes(x = Country, fill = Nicotine)) + geom_bar(position = "fill")
grid.arrange(p1,p2,p3,p4)
```

```{r}
p1 = ggplot(train, aes(x = Ethnicity, fill = Nicotine)) + geom_bar(position = "fill")
p2 = ggplot(train, aes(x = Nscore, fill = Nicotine)) + geom_bar(position = "fill")
p3 = ggplot(train, aes(x = Escore, fill = Nicotine)) + geom_bar(position = "fill")
p4 = ggplot(train, aes(x = Oscore, fill = Nicotine)) + geom_bar(position = "fill")
grid.arrange(p1,p2,p3,p4)
```

```{r}
p1 = ggplot(train, aes(x = Ascore, fill = Nicotine)) + geom_bar(position = "fill")
p2 = ggplot(train, aes(x = Cscore, fill = Nicotine)) + geom_bar(position = "fill")
p3 = ggplot(train, aes(x = Impulsive, fill = Nicotine)) + geom_bar(position = "fill")
p4 = ggplot(train, aes(x = SS, fill = Nicotine)) + geom_bar(position = "fill")
grid.arrange(p1,p2,p3,p4)

```



```{r Question 4}

#True/False: Individuals with higher “Impulsive” scores more likely to be Nicotine users than not.

# TRUE

```


```{r Question 5}

# Create a random forest model (using the ranger package) on the training set to predict Nicotine using all of the variables in the dataset. You 5-fold, k-fold cross-validation (random number seed of 123 for the folds). Allow R to select mtry values between 2 and 8 and min_n values between 5 and 20. Use 10 levels in your “grid_regular” function. Set a random number seed of 123 for the tune_grid function. Use 100 trees.

drug_recipe = recipe(Nicotine ~., train) %>%
  step_dummy(all_nominal(), -all_outcomes())

drug_model = rand_forest(mtry = tune(), min_n = tune(), trees = 100) %>% 
  set_engine("ranger", importance = "permutation") %>% #added importance metric
  set_mode("classification")

drug_wflow = 
  workflow() %>% 
  add_model(drug_model) %>% 
  add_recipe(drug_recipe)

drug_grid = grid_regular(
  mtry(range = c(2, 8)), #these values determined through significant trial and error
  min_n(range = c(5, 20)), #these values determined through significant trial and error
  levels = 10)

set.seed(123)
drug_folds = vfold_cv(train, v = 5)

set.seed(123)
drug_res_tuned = tune_grid(
  drug_wflow,
  resamples = drug_folds,
  grid = drug_grid)

```

```{r}

drug_res_tuned %>%
  collect_metrics() %>%
  filter(.metric == "accuracy") %>%
  select(mean, min_n, mtry) %>%
  pivot_longer(min_n:mtry,
    values_to = "value",
    names_to = "parameter"
  ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "Accuracy")

```
An alternate view of the parameters  
```{r}

drug_res_tuned %>%
  collect_metrics() %>%
  filter(.metric == "accuracy") %>%
  mutate(min_n = factor(min_n)) %>%
  ggplot(aes(mtry, mean, color = min_n)) +
  geom_line(alpha = 0.5, size = 1.5) +
  geom_point() +
  labs(y = "Accuracy")

# NOTE: This model may take a few minutes to run. Be patient :)
# Visualize the relationships between parameters and performance metrics.
# The highest accuracy in this visualization is just greater than which value:
# 

#---------> B. 0.730

```


```{r Question 6}

best_drug = select_best(drug_res_tuned, "accuracy") #mtry = 4, min_n = 8

# drug_grid_2 = grid_regular(
#   mtry(4), 
#   min_n(8),
#   levels = 10)
# 
# set.seed(123)
# drug_res_tuned_final = tune_grid(
#   drug_wflow,
#   resamples = drug_folds,
#   grid = drug_grid_2)
# 
# best_drug = select_best(drug_res_tuned_final, "accuracy") #mtry = 4, min_n = 8

set.seed(123)
final_rf = finalize_workflow(
  drug_wflow,
  best_drug)

#final_rf
```

```{r}
#fit the finalized workflow to our training data
final_rf_fit = fit(final_rf, train)

final_rf_fit %>% pull_workflow_fit() %>% vip(geom = "point")

# Use the best mtry and min_n values from Question 5 to finalize the workflow and fit the model to training set. Examine variable importance.

# Which variable is most important?
#------------> D. SS

```


```{r Question 7}

# To four decimal places, what is the accuracy of your model on the training set?

#---------->0.9363

trainpredrf = predict(final_rf_fit, train)
head(trainpredrf)

confusionMatrix(trainpredrf$.pred_class, train$Nicotine, 
                positive = "Yes")

```


```{r Question 8}

# To four decimal places, what is the naive accuracy (training set)?

#-----------------> 0.6707

```


```{r Question 9}

# To four decimal places, what is your model’s accuracy on the testing set?

testpredrf = predict(final_rf_fit, test)
head(testpredrf)

confusionMatrix(testpredrf$.pred_class, test$Nicotine, 
                positive = "Yes")

#---------->0.7090

```


```{r Question 10}

# The difference in accuracy between the training and testing sets implies?
# B. Overfitting is likely occurring

```